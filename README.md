# ICASSP2025

This repository contains code, Jupyter notebooks, and models for experiments with **AASIST2** and **Cross-Attention BiLSTM** classifiers.  
Both **single features** and **fusion features** are tested across the two classifiers.

---

## ðŸ”¹ Introduction
ICASSP2025 explores the performance of two deep learning classifiers on audio-based tasks:
- **AASIST2**
- **Cross-Attention BiLSTM**

The experiments evaluate both **single feature** and **feature fusion** setups to investigate how different representations impact classification performance.

---

## ðŸ”¹ Models
- **AASIST2**  
  A robust neural architecture tailored for speech/audio classification and spoof detection tasks.

- **Cross-Attention BiLSTM**  
  A bidirectional LSTM model enhanced with a **cross-attention mechanism**, designed to better capture dependencies across multiple feature streams.

---

## ðŸ”¹ Features
- **Single Features**: Each acoustic feature is tested individually.  
- **Fusion Features**: Combinations of multiple features fused before classification.

Typical features may include:
- Spectral features  
- Prosodic features  
- Other handcrafted or learned features  

---
